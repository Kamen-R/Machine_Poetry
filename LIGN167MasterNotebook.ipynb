{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import re\n",
        "import time\n",
        "\n",
        "import openai\n",
        "openai.api_key = 'FIX ME: insert key here'\n",
        "\n",
        "current_tokens = 0\n",
        "# Maximum tokens program is allowed to request before timing out\n",
        "max_tokens = 400\n",
        "def generate_words_and_spend_money(prompt, poem):\n",
        "    global current_tokens\n",
        "    global max_tokens\n",
        "    if current_tokens >= max_tokens:\n",
        "        print('Tokens expended')\n",
        "        print(poem)\n",
        "        raise TimeoutError\n",
        "    current_tokens += 1\n",
        "    line = openai.Completion.create(\n",
        "    model=\"text-davinci-003\",\n",
        "    prompt=\"{}:\\n\\n{}\".format(prompt, poem),\n",
        "    max_tokens=1,\n",
        "    temperature=0.9,\n",
        "    logprobs=5\n",
        "    )\n",
        "    choices = line[\"choices\"][0][\"logprobs\"][\"top_logprobs\"][0]\n",
        "    words = []\n",
        "    record = set()\n",
        "    for choice in choices.keys():\n",
        "        word = re.sub('(^ +)|( +$)', '', choice)\n",
        "        id = re.sub('[^A-Z]', '', word.upper())\n",
        "        prob = choices[choice]\n",
        "        if len(poem) > 0 and poem[-1] == '\\n' and choice.find('\\n') != -1:\n",
        "            continue\n",
        "        if id not in record and choice.find('\\\\') == -1 and choice.find('/') == -1 and prob > -10 and re.sub('[0-9]', '', choice) != '':\n",
        "            done = False\n",
        "            for i in range(len(words)):\n",
        "                if choices[words[i]] < prob:\n",
        "                    words.insert(i, choice)\n",
        "                    done = True\n",
        "                    break\n",
        "            if not done:\n",
        "                words.append(choice)\n",
        "            record.add(id)\n",
        "    print(words)\n",
        "    print(choices)\n",
        "    time.sleep(3)\n",
        "    return words\n",
        "\n",
        "# Loads the modified CMU dictionary and the list of unstressed words\n",
        "def load_data():\n",
        "    cmu_dictionary = {}\n",
        "    unstressed_words = set()\n",
        "    with open('Modified_CMU.txt','r',encoding=\"utf8\") as f:\n",
        "        for line in f:\n",
        "            entry = line.replace(\"\\n\", \"\").split('  ')\n",
        "            if entry[0] in cmu_dictionary:\n",
        "                cmu_dictionary[entry[0]].append(entry[1])\n",
        "            else:\n",
        "                cmu_dictionary[entry[0]] = [entry[1]]\n",
        "    cmu_dictionary[''] = ['']\n",
        "    with open('unstressed_words.txt','r',encoding=\"utf8\") as f:\n",
        "        for line in f:\n",
        "            unstressed_words.add(line.replace(\"\\n\", \"\"))\n",
        "    return cmu_dictionary, unstressed_words\n",
        "\n",
        "# Given a list of words representing a line, returns a list of sets of all possible stress patterns for each word in the line in order\n",
        "def get_line_stress_patterns(line, cmu_dictionary, unstressed_words):\n",
        "    stress_patterns = []\n",
        "    for word in line:\n",
        "        stress_patterns.append(get_stress_patterns(word, cmu_dictionary, unstressed_words))\n",
        "    return stress_patterns\n",
        "\n",
        "# Returns a set of the possible stress patterns of the input word\n",
        "def get_stress_patterns(word, cmu_dictionary, unstressed_words):\n",
        "    word = word.upper()\n",
        "    if word in unstressed_words:\n",
        "        return {'\\''}\n",
        "    if word not in cmu_dictionary:\n",
        "        return set()\n",
        "    stress_patterns = set()\n",
        "    for entry in cmu_dictionary[word]:\n",
        "        stress_patterns.add(cmu_to_stress_pattern(entry))\n",
        "    return stress_patterns\n",
        "\n",
        "# Given an entry from the CMU dictionary, converts it to a stress pattern\n",
        "def cmu_to_stress_pattern(entry):\n",
        "    stress_as_numbers = re.sub('[^0-2]', '', entry)\n",
        "    if len(stress_as_numbers) == 1:\n",
        "        return stress_as_numbers.replace('0', '.').replace('2', '~').replace('1', '~')\n",
        "    if stress_as_numbers.find('1') > -1:\n",
        "        return stress_as_numbers.replace('0', '.').replace('2', '.').replace('1', '-')\n",
        "    else:\n",
        "        return stress_as_numbers.replace('0', '.').replace('2', '-')\n",
        "\n",
        "# Checks if the given line matches any of the possible meter stresses\n",
        "# 0 means no, 1 means on track, 2 means yes\n",
        "def matches_meter(line, meter_stresses, cmu_dictionary, unstressed_words):\n",
        "    return some_stress_pattern_matches('', get_line_stress_patterns(line, cmu_dictionary, unstressed_words), meter_stresses)\n",
        "\n",
        "# Checks if a given representation of possible line stresses can match a given representation of meter stresses\n",
        "# 0 means no, 1 means on track, 2 means yes\n",
        "def some_stress_pattern_matches(line_stress, stress_patterns, meter_stresses):\n",
        "    match_type = 0\n",
        "    if len(stress_patterns) == 0:\n",
        "        for meter_stress in meter_stresses:\n",
        "            result = stresses_match(line_stress, meter_stress)\n",
        "            if result > match_type:\n",
        "                match_type = result\n",
        "                if match_type == 2:\n",
        "                    return match_type\n",
        "        return match_type\n",
        "    for stress_pattern in stress_patterns[0]:\n",
        "        result = some_stress_pattern_matches(line_stress + stress_pattern, stress_patterns[1:], meter_stresses)\n",
        "        if result > match_type:\n",
        "            match_type = result\n",
        "            if match_type == 2:\n",
        "                return match_type\n",
        "    return match_type\n",
        "\n",
        "# Return a tuple of match (0 = no, 1 = partial, 2 = full), pattern (list of stress patterns\n",
        "# corresponding to each word in the line)\n",
        "def scan_line(line, meter_stresses, cmu_dictionary, unstressed_words):\n",
        "    stress_patterns = get_line_stress_patterns(line, cmu_dictionary, unstressed_words)\n",
        "    return find_matching_stress_pattern([], stress_patterns, meter_stresses)\n",
        "\n",
        "# Return a tuple of match, pattern, in which match is 0 no match, 1 part match, 2 full match,\n",
        "# and pattern is a list of the stresses in the order used\n",
        "def find_matching_stress_pattern(line_stress, stress_patterns, meter_stresses):\n",
        "    match_type = 0\n",
        "    match_stress = []\n",
        "    if len(stress_patterns) == 0:\n",
        "        for meter_stress in meter_stresses:\n",
        "            result = stress_list_matches(line_stress, meter_stress)\n",
        "            if result > match_type:\n",
        "                match_type = result\n",
        "                match_stress = line_stress\n",
        "                if match_type == 2:\n",
        "                    return match_type, match_stress\n",
        "        return match_type, match_stress\n",
        "    for stress_pattern in stress_patterns[0]:\n",
        "        line_stress.append(stress_pattern)\n",
        "        result = find_matching_stress_pattern(line_stress, stress_patterns[1:], meter_stresses)\n",
        "        if result[0] > match_type:\n",
        "            match_type = result[0]\n",
        "            match_stress = result[1]\n",
        "            if match_type == 2:\n",
        "                return match_type, match_stress\n",
        "        line_stress.pop()\n",
        "    return match_type, match_stress\n",
        "\n",
        "# Checks if the pattern in line_stress matches with the pattern in meter_stress\n",
        "# 0 means no, 1 means on track, 2 means yes\n",
        "def stresses_match(line_stress, meter_stress):\n",
        "    if len(line_stress) > len(meter_stress):\n",
        "        return 0\n",
        "    match_type = 2\n",
        "    while len(line_stress) < len(meter_stress):\n",
        "        line_stress += '.'\n",
        "        match_type = 1\n",
        "    padded_line_stress = '.' + line_stress + '.'\n",
        "    for x in range(len(meter_stress)):\n",
        "        if line_stress[x] == '-' and meter_stress[x] == '.':\n",
        "            return 0\n",
        "        if meter_stress[x] == '-' and re.match('.\\'[~-] | [~-]\\'.', padded_line_stress[x : x + 3]) is not None:\n",
        "            return 0\n",
        "        if meter_stress[x] == '.' and re.match('[.\\']~[.\\']', padded_line_stress[x : x + 3]) is not None:\n",
        "            return 0\n",
        "    return match_type\n",
        "\n",
        "# Generates a random list of words from the dictionary\n",
        "def generate_words(cmu_dictionary):\n",
        "    words = []\n",
        "    for x in range(random.randrange(3, 9)):\n",
        "        words.append(random.choice(list(cmu_dictionary)))\n",
        "    return words\n",
        "\n",
        "# Generates a list representing a line using generate_words in the given meter\n",
        "def generate_line(line, meter_stresses, cmu_dictionary, unstressed_words):\n",
        "    match = matches_meter(line, meter_stresses, cmu_dictionary, unstressed_words)\n",
        "    if match == 2:\n",
        "        return line\n",
        "    if match == 1:\n",
        "        for word in generate_words(cmu_dictionary):\n",
        "            line.append(word)\n",
        "            result = generate_line(line, meter_stresses, cmu_dictionary, unstressed_words)\n",
        "            if result is not None:\n",
        "                return result\n",
        "            line.pop()\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "# Given a word, returns a set of all possible rhyme patterns represented as strings\n",
        "def get_rhyme_patterns(word, cmu_dictionary):\n",
        "    word = word.upper()\n",
        "    if word not in cmu_dictionary:\n",
        "        return set()\n",
        "    rhyme_patterns = set()\n",
        "    for entry in cmu_dictionary[word]:\n",
        "        rhyme_patterns.update(cmu_to_rhyme_patterns(entry))\n",
        "    return rhyme_patterns\n",
        "\n",
        "# Given an entry from the CMU dictionary, converts it to a list of possible rhyme patterns represented as strings\n",
        "def cmu_to_rhyme_patterns(entry):\n",
        "    match = re.search('([A-Z]+1)( [A-Z02]+)*$', entry)\n",
        "    if match is not None:\n",
        "        return [match.group(0)]\n",
        "    match = re.search('([A-Z]+2)( [A-Z0]+)*$', entry)\n",
        "    if match is not None:\n",
        "        return [match.group(0)]\n",
        "    phonemes = entry.split(' ')\n",
        "    index = len(phonemes) - 1\n",
        "    rhyme_patterns = ['']\n",
        "    while index >= 0:\n",
        "        rhyme_patterns[-1] = phonemes[index] + ' ' + rhyme_patterns[-1]\n",
        "        if phonemes[index].find('0') != -1:\n",
        "            rhyme_patterns.insert(-1, rhyme_patterns[-1][:-1])\n",
        "        index -= 1\n",
        "    return rhyme_patterns[:-1]\n",
        "\n",
        "# Given two words, returns True if the words rhyme and False if they do not\n",
        "def words_rhyme(word1, word2, cmu_dictionary):\n",
        "    rhymes1 = get_rhyme_patterns(word1, cmu_dictionary)\n",
        "    rhymes2 = get_rhyme_patterns(word2, cmu_dictionary)\n",
        "    for rhyme1 in rhymes1:\n",
        "        for rhyme2 in rhymes2:\n",
        "            if rhyme1 == rhyme2:\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "# Given two lines represented by lists of words, return True if the lines rhyme and False if they do not\n",
        "def lines_rhyme(line1, line2, cmu_dictionary):\n",
        "    return words_rhyme(line1[-1], line2[-1], cmu_dictionary)\n",
        "\n",
        "# Concatenate a list of tokens\n",
        "def tokens_to_text(tokens):\n",
        "    text = ''\n",
        "    for token in tokens:\n",
        "        text += token\n",
        "    return text\n",
        "\n",
        "# Convert a string into a list representing a line\n",
        "def line_text_to_list(line):\n",
        "    return re.sub('(^ )|( $)', '', re.sub(' +', ' ', re.sub('[^A-Z ]', ' ', line.upper()))).split(' ')\n",
        "\n",
        "# Convert text into a list of lists representing lines\n",
        "def text_to_line_list(text):\n",
        "    lines = []\n",
        "    for line in re.sub('(^\\n)|(\\n$)', '', re.sub('\\n+', '\\n', re.sub('[^A-Z \\n]', '', text.upper()))).split('\\n'):\n",
        "        line_list = line_text_to_list(line)\n",
        "        if len(line_list) != 1 or line_list[0] != '':\n",
        "            lines.append(line_list)\n",
        "    if len(lines) == 0:\n",
        "        return ['']\n",
        "    return lines\n",
        "\n",
        "# Return 2 if the poem is an exact match, 1 if it is a partial match, and 0 if it does not match\n",
        "def poem_matches(text, meter_stresses_list, rhyme_scheme, cmu_dictionary, unstressed_words):\n",
        "\n",
        "    lines = text_to_line_list(text)\n",
        "\n",
        "    if len(lines) > len(rhyme_scheme):\n",
        "        return 0\n",
        "\n",
        "    last_match = matches_meter(lines[-1], meter_stresses_list[len(lines) - 1], cmu_dictionary, unstressed_words)\n",
        "\n",
        "    match_type = 2\n",
        "    \n",
        "    if len(text) > 0 and text[-1] != '!' and  text[-1] != '.' and text[-1] != '>' and text[-1] != ',':\n",
        "        match_type = 1\n",
        "\n",
        "    if last_match == 0:\n",
        "        return 0\n",
        "    \n",
        "    if last_match == 1:\n",
        "        lines.pop()\n",
        "\n",
        "    if len(lines) != len(rhyme_scheme):\n",
        "        match_type = 1\n",
        "    \n",
        "    rhyming_lines = {}\n",
        "\n",
        "    for i in range(len(lines)):\n",
        "        if rhyme_scheme[i] != '*' and rhyme_scheme[i] in rhyming_lines:\n",
        "            rhyming_lines[rhyme_scheme[i]].append(i)\n",
        "        else:\n",
        "            rhyming_lines[rhyme_scheme[i]] = [i]\n",
        "    \n",
        "    for i in range(len(lines)):\n",
        "        match = matches_meter(lines[i], meter_stresses_list[i], cmu_dictionary, unstressed_words)\n",
        "        if match != 2:\n",
        "            return 0\n",
        "        for j in rhyming_lines[rhyme_scheme[i]]:\n",
        "            if j >= i:\n",
        "                break\n",
        "            if not lines_rhyme(lines[i], lines[j], cmu_dictionary):\n",
        "                return 0\n",
        "    \n",
        "    return match_type\n",
        "\n",
        "\n",
        "# Generates a random list of words from the dictionary\n",
        "def generate_words_and_lines(cmu_dictionary):\n",
        "    words = random.choice([[], ['\\n']])\n",
        "    for x in range(random.randrange(3, 9)):\n",
        "        words.append(random.choice(list(cmu_dictionary)))\n",
        "    return words\n",
        "\n",
        "# Generates a list representing a line using generate_words in the given meter\n",
        "def generate_poem(text, meter_stresses, rhyme_scheme, cmu_dictionary, unstressed_words):\n",
        "    match = poem_matches(text, meter_stresses, rhyme_scheme, cmu_dictionary, unstressed_words)\n",
        "    if match == 2:\n",
        "        return text\n",
        "    if match == 1:\n",
        "        for word in generate_words_and_lines(cmu_dictionary):\n",
        "            text += ' ' + word\n",
        "            result = generate_poem(text, meter_stresses, rhyme_scheme, cmu_dictionary, unstressed_words)\n",
        "            if result is not None:\n",
        "                return result\n",
        "            text = re.sub(' [^ ]+$', '', text)\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "# Generates a list representing a line using generate_words in the given meter\n",
        "def generate_poem_and_spend_money(prompt, text, meter_stresses, rhyme_scheme, cmu_dictionary, unstressed_words):\n",
        "    match = poem_matches(text, meter_stresses, rhyme_scheme, cmu_dictionary, unstressed_words)\n",
        "    if match == 2:\n",
        "        return text\n",
        "    if match == 1:\n",
        "        for word in generate_words_and_spend_money(prompt, text):\n",
        "            text += word\n",
        "            print(text)\n",
        "            result = generate_poem_and_spend_money(prompt, text, meter_stresses, rhyme_scheme, cmu_dictionary, unstressed_words)\n",
        "            if result is not None:\n",
        "                return result\n",
        "            text = text[:len(text) - len(word)]\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "# Load necessary files\n",
        "cmu_dictionary, unstressed_words = load_data()\n",
        "\n",
        "sonnet_stresses = ['.-.-.-.-.-', '-..-.-.-.-', '.-.-.-.-.-.', '-..-.-.-.-.']\n",
        "five = ['*****']\n",
        "seven = ['*******']\n",
        "\n",
        "sonnet_lines = []\n",
        "for i in range(14):\n",
        "    sonnet_lines.append(sonnet_stresses)\n",
        "\n",
        "haiku_lines = [five, seven, five]\n",
        "\n",
        "sonnet_rhyme_scheme = 'ABABCDCDEFEFGG'\n",
        "haiku_rhyme_scheme = '***'\n",
        "\n",
        "haiku = generate_poem_and_spend_money('Generate a haiku about linguistics:', '', haiku_lines, haiku_rhyme_scheme, cmu_dictionary, unstressed_words)\n",
        "print(current_tokens)\n",
        "print(max_tokens)\n",
        "\n",
        "sonnet = generate_poem_and_spend_money('Generate a sonnet about machine learning:', '', sonnet_lines, sonnet_rhyme_scheme, cmu_dictionary, unstressed_words)\n",
        "print(current_tokens)\n",
        "print(max_tokens)\n",
        "\n",
        "print(haiku)\n",
        "print(sonnet)\n",
        "\n",
        "#print(scan_line(line_text_to_list('And help us to make a better land!'), sonnet_stresses, cmu_dictionary, unstressed_words))"
      ],
      "metadata": {
        "id": "ohZDI4djowaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install spacy_syllables\n",
        "import os\n",
        "import openai\n",
        "import spacy\n",
        "from spacy_syllables import SpacySyllables\n",
        "openai.api_key = \"API_KEY_HERE\"\n",
        "import nltk\n",
        "nltk.download('cmudict')\n",
        "from nltk.corpus import cmudict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F2cvoFEGG-S",
        "outputId": "62da3e2f-de73-4afe-fea6-701f2ec1b65b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 1.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.1.1)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.221124-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 16.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.6.0.1-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=94a5a5ce4560bf03c1b8fdd0aef6b99a2e153501f749bbffb743e1fe8e2e686b\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "Successfully built openai\n",
            "Installing collected packages: types-pytz, pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.5.2.221124 types-pytz-2022.6.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy_syllables\n",
            "  Downloading spacy_syllables-3.0.1-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.0.3 in /usr/local/lib/python3.8/dist-packages (from spacy_syllables) (3.4.3)\n",
            "Collecting pyphen<0.11.0,>=0.10.0\n",
            "  Downloading Pyphen-0.10.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (1.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (4.64.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (0.7.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (3.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (2.4.5)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (8.1.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (1.10.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (1.0.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (3.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (2.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (2.0.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (3.0.10)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.3->spacy_syllables) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<4.0.0,>=3.0.3->spacy_syllables) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.0.3->spacy_syllables) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<4.0.0,>=3.0.3->spacy_syllables) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.3->spacy_syllables) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.3->spacy_syllables) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.3->spacy_syllables) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.3->spacy_syllables) (2022.9.24)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.0.3->spacy_syllables) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.0.3->spacy_syllables) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.0.3->spacy_syllables) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<4.0.0,>=3.0.3->spacy_syllables) (2.0.1)\n",
            "Installing collected packages: pyphen, spacy-syllables\n",
            "Successfully installed pyphen-0.10.0 spacy-syllables-3.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libenchant1c2a\n",
        "!pip install pyenchant\n",
        "#!pip3 install pyenchant==1.6.6\n",
        "import enchant\n",
        "d = enchant.Dict(\"en_US\")\n",
        "d.check(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18XMp_ddq51u",
        "outputId": "434e9d85-3424-4028-9dca-9880d8fc172f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libhunspell-1.6-0 libtext-iconv-perl\n",
            "Suggested packages:\n",
            "  aspell-doc spellutils wordlist hunspell openoffice.org-hunspell\n",
            "  | openoffice.org-core libenchant-voikko\n",
            "The following NEW packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n",
            "0 upgraded, 10 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 1,312 kB of archives.\n",
            "After this operation, 5,353 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtext-iconv-perl amd64 1.7-5build6 [13.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libaspell15 amd64 0.60.7~20110707-4ubuntu0.2 [310 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 emacsen-common all 2.0.8 [17.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 dictionaries-common all 1.27.2 [186 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 aspell amd64 0.60.7~20110707-4ubuntu0.2 [87.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 aspell-en all 2017.08.24-0-0.1 [298 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 hunspell-en-us all 1:2017.08.24 [168 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhunspell-1.6-0 amd64 1.6.2-1 [154 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libenchant1c2a amd64 1.6.0-11.1 [64.4 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 enchant amd64 1.6.0-11.1 [12.2 kB]\n",
            "Fetched 1,312 kB in 1s (1,076 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 10.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libtext-iconv-perl.\n",
            "(Reading database ... 124015 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libtext-iconv-perl_1.7-5build6_amd64.deb ...\n",
            "Unpacking libtext-iconv-perl (1.7-5build6) ...\n",
            "Selecting previously unselected package libaspell15:amd64.\n",
            "Preparing to unpack .../1-libaspell15_0.60.7~20110707-4ubuntu0.2_amd64.deb ...\n",
            "Unpacking libaspell15:amd64 (0.60.7~20110707-4ubuntu0.2) ...\n",
            "Selecting previously unselected package emacsen-common.\n",
            "Preparing to unpack .../2-emacsen-common_2.0.8_all.deb ...\n",
            "Unpacking emacsen-common (2.0.8) ...\n",
            "Selecting previously unselected package dictionaries-common.\n",
            "Preparing to unpack .../3-dictionaries-common_1.27.2_all.deb ...\n",
            "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n",
            "Unpacking dictionaries-common (1.27.2) ...\n",
            "Selecting previously unselected package aspell.\n",
            "Preparing to unpack .../4-aspell_0.60.7~20110707-4ubuntu0.2_amd64.deb ...\n",
            "Unpacking aspell (0.60.7~20110707-4ubuntu0.2) ...\n",
            "Selecting previously unselected package aspell-en.\n",
            "Preparing to unpack .../5-aspell-en_2017.08.24-0-0.1_all.deb ...\n",
            "Unpacking aspell-en (2017.08.24-0-0.1) ...\n",
            "Selecting previously unselected package hunspell-en-us.\n",
            "Preparing to unpack .../6-hunspell-en-us_1%3a2017.08.24_all.deb ...\n",
            "Unpacking hunspell-en-us (1:2017.08.24) ...\n",
            "Selecting previously unselected package libhunspell-1.6-0:amd64.\n",
            "Preparing to unpack .../7-libhunspell-1.6-0_1.6.2-1_amd64.deb ...\n",
            "Unpacking libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Selecting previously unselected package libenchant1c2a:amd64.\n",
            "Preparing to unpack .../8-libenchant1c2a_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Selecting previously unselected package enchant.\n",
            "Preparing to unpack .../9-enchant_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking enchant (1.6.0-11.1) ...\n",
            "Setting up libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Setting up libaspell15:amd64 (0.60.7~20110707-4ubuntu0.2) ...\n",
            "Setting up emacsen-common (2.0.8) ...\n",
            "Setting up libtext-iconv-perl (1.7-5build6) ...\n",
            "Setting up dictionaries-common (1.27.2) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up aspell (0.60.7~20110707-4ubuntu0.2) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up hunspell-en-us (1:2017.08.24) ...\n",
            "Setting up libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Setting up aspell-en (2017.08.24-0-0.1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up enchant (1.6.0-11.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for dictionaries-common (1.27.2) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "aspell-autobuildhash: processing: en [en-common].\n",
            "aspell-autobuildhash: processing: en [en-variant_0].\n",
            "aspell-autobuildhash: processing: en [en-variant_1].\n",
            "aspell-autobuildhash: processing: en [en-variant_2].\n",
            "aspell-autobuildhash: processing: en [en-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_AU-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_CA-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_US-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_US-wo_accents-only].\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyenchant\n",
            "  Downloading pyenchant-3.2.2-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyenchant\n",
            "Successfully installed pyenchant-3.2.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_syllable_word(word):\n",
        "  \"\"\"\n",
        "  input a string word\n",
        "  uses cmu_dictionary to get stress digits of word\n",
        "  output is total syllables of the word\n",
        "  \"\"\"\n",
        "\n",
        "  stress = cmudict.dict()[word.lower()] # using stress to count syllables \n",
        "  syllable_count=0\n",
        "\n",
        "  for string in stress[0]:\n",
        "    for x in string:\n",
        "      if any(char.isdigit() for char in x): #count digits\n",
        "        syllable_count += 1\n",
        "\n",
        "  return syllable_count\n",
        "\n",
        "def generate_line(doc, count):\n",
        "  \"\"\"\n",
        "  generates line form poem. \n",
        "  Input gpt-3 doc, and count for line\n",
        "  takes care of cases with punctuations and newline char from doc,\n",
        "  puts spaces after words, and removes additional spaces\n",
        "  outputs the line and the total syllables in line\n",
        "  \"\"\"\n",
        "  curr_text = \"\"\n",
        "  sent_count = 0 \n",
        "  for word in doc:\n",
        "    word_count = 0\n",
        "    if word.isalpha():\n",
        "      word_count = get_syllable_word(word)\n",
        "    \n",
        "      if (sent_count + word_count) > count:\n",
        "        return curr_text[:-1], sent_count\n",
        "      else:\n",
        "        curr_text += word + \" \"\n",
        "        sent_count += word_count\n",
        "    \n",
        "    else:\n",
        "      if (word == \"\\n\" or word == \"\\n\\n\") and (sent_count == 0):\n",
        "          curr_text = curr_text[:-1]\n",
        "          curr_text += word\n",
        "      else:\n",
        "          return curr_text[:-1], sent_count\n",
        "       \n",
        "  return curr_text[:-1], sent_count\n",
        "\n",
        "def gen_text(prompt, num_tokens, poem):\n",
        "  tokens_gen = num_tokens\n",
        "\n",
        "  # create first line\n",
        "  #when poem is empty\n",
        "  if poem == '':\n",
        "    line = openai.Completion.create(\n",
        "    model=\"text-davinci-003\",\n",
        "    prompt=\"Generate a haiku about with the prompt: {}\".format(prompt),\n",
        "    max_tokens=tokens_gen,\n",
        "    temperature=0,\n",
        "    logprobs=5\n",
        "    )\n",
        "    return line\n",
        "# when the poem is not empty\n",
        "  line = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=\"Write the next line of a haiku that starts with the line(s): \\\"{}\\\". The prompt of the poem is: {}\".format(poem,prompt),\n",
        "  max_tokens=tokens_gen,\n",
        "  temperature=0,\n",
        "  logprobs=5\n",
        "  )\n",
        "  return line\n",
        "\n",
        "def choose_new_token(line, curr_text, sent_count, line_count):\n",
        "  english = enchant.Dict(\"en_US\")\n",
        "  log_text = \"\"\n",
        "  #print(line)\n",
        "  #iterations = []\n",
        "  #print(line[\"choices\"][0][\"logprobs\"][\"top_logprobs\"])\n",
        "  for option in line[\"choices\"][0][\"logprobs\"][\"top_logprobs\"]:\n",
        "    if log_text != curr_text:\n",
        "      log_text += max(option, key=option.get)\n",
        "      #iterations.append([log_text, curr_text, log_text==curr_text])\n",
        "    else:\n",
        "      print(\"EQUAL!\")\n",
        "      selected = max(option, key=option.get)\n",
        "      option.pop(selected)\n",
        "      while len(option) > 0:\n",
        "        word_count = 0\n",
        "        selected = max(option, key=option.get)\n",
        "        if selected == \" \":\n",
        "          log_text += selected\n",
        "          #print(iterations)\n",
        "          return log_text, sent_count\n",
        "        if selected == \".\": # edge case where . passes through the english word check\n",
        "          option.pop(selected)\n",
        "          continue\n",
        "        #print(selected, word_count)\n",
        "        if english.check(selected.replace(\" \", \"\")):\n",
        "          word_count = get_syllable_word(selected.replace(\" \", \"\"))\n",
        "        \n",
        "          if (sent_count + word_count) == line_count:\n",
        "            #print(selected, word_count, sent_count, log_text)\n",
        "            log_text += selected\n",
        "            sent_count += word_count\n",
        "            #print(iterations)\n",
        "            return log_text, sent_count\n",
        "        option.pop(selected)\n",
        "  #print(iterations)           \n",
        "  return log_text, sent_count\n",
        "\n",
        "def find_last_word(sent, num_syllables):\n",
        "  english = enchant.Dict(\"en_US\")\n",
        "  last_word = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=\"Finish this sentence of a poem with one word that best fits.: \\\"{}\\\"\".format(sent),\n",
        "  max_tokens=5,\n",
        "  temperature=0,\n",
        "  logprobs=5\n",
        "  )\n",
        "  ans = last_word[\"choices\"][0][\"text\"].replace(\"\\n\", \"\")\n",
        "\n",
        "  if english.check(ans) and get_syllable_word(ans) == num_syllables:\n",
        "    return ans\n",
        "  else:\n",
        "    word = \"\"\n",
        "    token_count = 0\n",
        "    for option in last_word[\"choices\"][0][\"logprobs\"][\"top_logprobs\"]:\n",
        "      if max(option, key=option.get).isalpha():\n",
        "        word += max(option, key=option.get)\n",
        "        if english.check(word):\n",
        "          if get_syllable_word(word) == num_syllables:\n",
        "            return word\n",
        "          else:\n",
        "            break\n",
        "      token_count += 1\n",
        "    \n",
        "    while token_count > 0:\n",
        "      for i in last_word[\"choices\"][0][\"logprobs\"][\"top_logprobs\"][token_count]:\n",
        "        if i.isalpha():\n",
        "          if english.check(i):\n",
        "            if get_syllable_word(i) == num_syllables:\n",
        "              return i\n",
        "      token_count -= 1\n",
        "    \n",
        "    return \"ERROR: NO GOOD OPTIONS\"\n",
        "\n",
        "def generate_poem(prompt, num_syllables, num_tokens, poem):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  nlp.add_pipe(\"syllables\", after=\"tagger\", config={\"lang\": \"en_US\"})\n",
        "  line = gen_text(prompt, num_tokens, poem)\n",
        "  #print(line[\"choices\"][0][\"text\"])\n",
        "  text = line[\"choices\"][0][\"text\"]#[len(poem):]\n",
        "  doc = nlp(text)\n",
        "  doc = [(token.text) for token in doc]\n",
        "  #counter = 0\n",
        "  #if len(poem) != 0:\n",
        "  #  substring = \"\"\n",
        "  #  for i in doc:\n",
        "  #    substring += i\n",
        "  #    if poem.find(substring) == -1:\n",
        "  #      break\n",
        "  #    counter += 1\n",
        "  #doc = doc[counter:]\n",
        "  #print(\"gen poem\", doc)\n",
        "  #print(poem)\n",
        "  curr_text = generate_line(doc, num_syllables)\n",
        "  print(curr_text)\n",
        "  if curr_text[1] != num_syllables:\n",
        "    new_text = choose_new_token(line, curr_text[0], curr_text[1], num_syllables)\n",
        "    print(new_text)\n",
        "    if new_text[1] != num_syllables:\n",
        "      print(num_syllables - new_text[1])\n",
        "      last = find_last_word(new_text[0], num_syllables - new_text[1])\n",
        "      return poem + new_text[0] + last\n",
        "    return poem + new_text[0]\n",
        "  \n",
        "  return poem + curr_text[0]\n",
        "\n",
        "def haiku_v3(prompt):\n",
        "  \n",
        "  line1 = generate_poem(prompt, 5, 15, \"\")\n",
        "  #print(\"print line 1\", line1)\n",
        "  line2 = generate_poem(prompt, 7, 45, line1)\n",
        "  #print(\"print line 2\", line2)\n",
        "  line3 = generate_poem(prompt, 5, 70, line2)\n",
        "  #print(\"print line 3\", line3)\n",
        "  return line3 "
      ],
      "metadata": {
        "id": "xJmtueL_48dZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "haiku_v3(\"\")"
      ],
      "metadata": {
        "id": "cfQ4-Z-JhHFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "haiku_v3(\"Astrology girl.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "wmFposXYjdAY",
        "outputId": "1af0136a-4aff-4792-eafc-ab38bd84646d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('\\n\\nMysterious girl', 5)\n",
            "('\\n\\nHer eyes tell stories of the', 7)\n",
            "('\\n\\nPast lives and stars', 4)\n",
            "EQUAL!\n",
            "('\\n\\nPast lives and stars that', 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nMysterious girl\\n\\nHer eyes tell stories of the\\n\\nPast lives and stars that'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "haiku_v3(\"Opening a door to the mind when using drugs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "Ar9VUoCVWFm_",
        "outputId": "10ec0cee-4ac7-4184-957a-3bbb40c7c57c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('\\n\\nOpening a door', 5)\n",
            "('\\n\\nA new world awaits', 5)\n",
            "EQUAL!\n",
            "('\\n\\nA new world awaits inside', 7)\n",
            "('\\n\\nThe mind expands', 4)\n",
            "EQUAL!\n",
            "('\\n\\nThe mind expands far', 5)\n",
            "CPU times: user 18 s, sys: 1.07 s, total: 19.1 s\n",
            "Wall time: 24.5 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nOpening a door\\n\\nA new world awaits inside\\n\\nThe mind expands far'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "haiku_v3(\"The seasons changing from Fall to Winter.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKrzEsz5PBYq",
        "outputId": "b6b91651-dab6-4db0-99e1-40e4bcdb8b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Leaves fall away, soon\n",
            "Snow will blanket the ground\n",
            "\n",
            "gen poem ['\\n\\n', 'Leaves', 'fall', 'away', ',', 'soon', '\\n', 'Snow', 'will', 'blanket', 'the', 'ground', '\\n']\n",
            "('\\n\\nLeaves fall away', 4)\n",
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"length\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": {\n",
            "        \"text_offset\": [\n",
            "          81,\n",
            "          82,\n",
            "          83,\n",
            "          85,\n",
            "          89,\n",
            "          94,\n",
            "          99,\n",
            "          100,\n",
            "          105,\n",
            "          106,\n",
            "          110,\n",
            "          115,\n",
            "          123,\n",
            "          127,\n",
            "          134\n",
            "        ],\n",
            "        \"token_logprobs\": [\n",
            "          -0.021073261,\n",
            "          -3.2616e-05,\n",
            "          -0.5703003,\n",
            "          -0.011517642,\n",
            "          -1.76789,\n",
            "          -1.6612957,\n",
            "          -1.1764408,\n",
            "          -1.1760604,\n",
            "          -0.22848402,\n",
            "          -0.6637858,\n",
            "          -1.1614192,\n",
            "          -0.7797424,\n",
            "          -0.056278076,\n",
            "          -0.5639004,\n",
            "          -0.23976663\n",
            "        ],\n",
            "        \"tokens\": [\n",
            "          \"\\n\",\n",
            "          \"\\n\",\n",
            "          \"Le\",\n",
            "          \"aves\",\n",
            "          \" fall\",\n",
            "          \" away\",\n",
            "          \",\",\n",
            "          \" soon\",\n",
            "          \"\\n\",\n",
            "          \"Snow\",\n",
            "          \" will\",\n",
            "          \" blanket\",\n",
            "          \" the\",\n",
            "          \" ground\",\n",
            "          \"\\n\"\n",
            "        ],\n",
            "        \"top_logprobs\": [\n",
            "          {\n",
            "            \"\\n\": -0.021073261,\n",
            "            \"\\n\\n\": -4.301177,\n",
            "            \" \": -4.9513493,\n",
            "            \"  \": -9.694109,\n",
            "            \" Leaves\": -10.810573\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -3.2616e-05,\n",
            "            \"\\n\\n\": -12.154839,\n",
            "            \" \": -12.05791,\n",
            "            \"A\": -13.315409,\n",
            "            \"The\": -11.487959\n",
            "          },\n",
            "          {\n",
            "            \"Aut\": -2.9015493,\n",
            "            \"Br\": -3.5209913,\n",
            "            \"Col\": -3.5065117,\n",
            "            \"Le\": -0.5703003,\n",
            "            \"The\": -2.014806\n",
            "          },\n",
            "          {\n",
            "            \"af\": -4.513339,\n",
            "            \"aning\": -11.442163,\n",
            "            \"aping\": -11.741878,\n",
            "            \"aves\": -0.011517642,\n",
            "            \"aving\": -7.752482\n",
            "          },\n",
            "          {\n",
            "            \" drift\": -3.1352282,\n",
            "            \" fall\": -1.76789,\n",
            "            \" falling\": -2.4940405,\n",
            "            \" of\": -2.0587606,\n",
            "            \" turn\": -2.5604687\n",
            "          },\n",
            "          {\n",
            "            \" and\": -2.242666,\n",
            "            \" away\": -1.6612957,\n",
            "            \" from\": -2.2859933,\n",
            "            \" in\": -2.2629993,\n",
            "            \",\": -2.2552564\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -1.596603,\n",
            "            \" fast\": -2.9713998,\n",
            "            \" now\": -3.012381,\n",
            "            \" soon\": -1.9084697,\n",
            "            \",\": -1.1764408\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -1.6059434,\n",
            "            \" chill\": -2.909231,\n",
            "            \" cold\": -2.495296,\n",
            "            \" snow\": -2.1900346,\n",
            "            \" soon\": -1.1760604\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -0.22848402,\n",
            "            \" \": -3.7212071,\n",
            "            \" replaced\": -4.6975164,\n",
            "            \" snow\": -2.111408,\n",
            "            \",\": -4.9234366\n",
            "          },\n",
            "          {\n",
            "            \"A\": -2.6010215,\n",
            "            \"F\": -3.1957774,\n",
            "            \"Snow\": -0.6637858,\n",
            "            \"The\": -2.840824,\n",
            "            \"Winter\": -2.3849437\n",
            "          },\n",
            "          {\n",
            "            \" blankets\": -1.9737284,\n",
            "            \" covers\": -3.204837,\n",
            "            \" will\": -1.1614192,\n",
            "            \"fl\": -1.3049289,\n",
            "            \"y\": -3.714945\n",
            "          },\n",
            "          {\n",
            "            \" blanket\": -0.7797424,\n",
            "            \" come\": -3.3778832,\n",
            "            \" cover\": -2.9995556,\n",
            "            \" fill\": -2.5933475,\n",
            "            \" take\": -2.2289505\n",
            "          },\n",
            "          {\n",
            "            \" all\": -4.380033,\n",
            "            \" the\": -0.056278076,\n",
            "            \" them\": -5.789951,\n",
            "            \" this\": -5.135045,\n",
            "            \" us\": -4.711924\n",
            "          },\n",
            "          {\n",
            "            \" Earth\": -3.5878863,\n",
            "            \" earth\": -1.6480602,\n",
            "            \" ground\": -0.5639004,\n",
            "            \" land\": -2.6298375,\n",
            "            \" trees\": -2.6944833\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -0.23976663,\n",
            "            \" \": -3.5652592,\n",
            "            \",\": -3.1204963,\n",
            "            \".\": -2.3845973,\n",
            "            \";\": -3.517733\n",
            "          }\n",
            "        ]\n",
            "      },\n",
            "      \"text\": \"\\n\\nLeaves fall away, soon\\nSnow will blanket the ground\\n\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1669870352,\n",
            "  \"id\": \"cmpl-6IVqi6oRwJNbDOhhcSXh2ipORsESx\",\n",
            "  \"model\": \"text-davinci-003\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 15,\n",
            "    \"prompt_tokens\": 18,\n",
            "    \"total_tokens\": 33\n",
            "  }\n",
            "}\n",
            "EQUAL!\n",
            "[['\\n', '\\n\\nLeaves fall away', False], ['\\n\\n', '\\n\\nLeaves fall away', False], ['\\n\\nLe', '\\n\\nLeaves fall away', False], ['\\n\\nLeaves', '\\n\\nLeaves fall away', False], ['\\n\\nLeaves fall', '\\n\\nLeaves fall away', False], ['\\n\\nLeaves fall away', '\\n\\nLeaves fall away', True]]\n",
            "('\\n\\nLeaves fall away soon', 5)\n",
            "print line 1 \n",
            "\n",
            "Leaves fall away soon\n",
            "\n",
            "\n",
            "The chill of winter air,\n",
            "Brings a new season of change.\n",
            "gen poem ['\\n\\n', 'The', 'chill', 'of', 'winter', 'air', ',', '\\n', 'Brings', 'a', 'new', 'season', 'of', 'change', '.']\n",
            "('\\n\\nThe chill of winter air', 6)\n",
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": {\n",
            "        \"text_offset\": [\n",
            "          156,\n",
            "          157,\n",
            "          158,\n",
            "          161,\n",
            "          167,\n",
            "          170,\n",
            "          177,\n",
            "          181,\n",
            "          182,\n",
            "          183,\n",
            "          185,\n",
            "          189,\n",
            "          191,\n",
            "          195,\n",
            "          202,\n",
            "          205,\n",
            "          212,\n",
            "          213,\n",
            "          213,\n",
            "          213,\n",
            "          213\n",
            "        ],\n",
            "        \"token_logprobs\": [\n",
            "          -0.029559577,\n",
            "          -8.149626e-05,\n",
            "          -1.7342472,\n",
            "          -1.0227902,\n",
            "          -0.40659705,\n",
            "          -0.21490897,\n",
            "          -1.0739076,\n",
            "          -0.65771,\n",
            "          -0.40622404,\n",
            "          -1.4657534,\n",
            "          -0.02375303,\n",
            "          -0.61839855,\n",
            "          -1.7028582,\n",
            "          -1.1125957,\n",
            "          -1.0125955,\n",
            "          -1.129323,\n",
            "          -0.12659872,\n",
            "          -0.38911083,\n",
            "          -0.26538202,\n",
            "          -0.03855895,\n",
            "          -0.7637307\n",
            "        ],\n",
            "        \"tokens\": [\n",
            "          \"\\n\",\n",
            "          \"\\n\",\n",
            "          \"The\",\n",
            "          \" chill\",\n",
            "          \" of\",\n",
            "          \" winter\",\n",
            "          \" air\",\n",
            "          \",\",\n",
            "          \"\\n\",\n",
            "          \"Br\",\n",
            "          \"ings\",\n",
            "          \" a\",\n",
            "          \" new\",\n",
            "          \" season\",\n",
            "          \" of\",\n",
            "          \" change\",\n",
            "          \".\",\n",
            "          \"<|endoftext|>\",\n",
            "          \" \\u00a7\\u00a7\",\n",
            "          \" FILE\",\n",
            "          \" READ\"\n",
            "        ],\n",
            "        \"top_logprobs\": [\n",
            "          {\n",
            "            \"\\n\": -0.029559577,\n",
            "            \"\\n\\n\": -6.7980666,\n",
            "            \" \": -3.5811608,\n",
            "            \"  \": -8.804525,\n",
            "            \"   \": -11.8416\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -8.149626e-05,\n",
            "            \"\\n\\n\": -14.826236,\n",
            "            \" \": -9.458682,\n",
            "            \"  \": -13.986189,\n",
            "            \"    \": -14.140004\n",
            "          },\n",
            "          {\n",
            "            \"Cold\": -2.5926838,\n",
            "            \"Snow\": -2.322772,\n",
            "            \"The\": -1.7342472,\n",
            "            \"Wind\": -3.0620544,\n",
            "            \"Winter\": -3.021371\n",
            "          },\n",
            "          {\n",
            "            \" air\": -2.90613,\n",
            "            \" chill\": -1.0227902,\n",
            "            \" cold\": -2.3950799,\n",
            "            \" sky\": -3.2790504,\n",
            "            \" snow\": -2.259802\n",
            "          },\n",
            "          {\n",
            "            \" air\": -3.3113818,\n",
            "            \" creeps\": -3.33877,\n",
            "            \" in\": -2.7661428,\n",
            "            \" of\": -0.40659705,\n",
            "            \" wind\": -3.1264215\n",
            "          },\n",
            "          {\n",
            "            \" Winter\": -1.985968,\n",
            "            \" night\": -5.512409,\n",
            "            \" snow\": -4.5601163,\n",
            "            \" the\": -3.6277418,\n",
            "            \" winter\": -0.21490897\n",
            "          },\n",
            "          {\n",
            "            \" air\": -1.0739076,\n",
            "            \" comes\": -2.9536207,\n",
            "            \" creeps\": -2.313956,\n",
            "            \" sets\": -3.1415315,\n",
            "            \" winds\": -2.439163\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -2.4298067,\n",
            "            \" \": -2.6987264,\n",
            "            \",\": -0.65771,\n",
            "            \"/\": -3.2267504,\n",
            "            \"<|endoftext|>\": -2.9645908\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -0.40622404,\n",
            "            \" \": -1.5339543,\n",
            "            \" /\": -4.4166226,\n",
            "            \"/\": -2.9834812,\n",
            "            \"<|endoftext|>\": -3.1467025\n",
            "          },\n",
            "          {\n",
            "            \"A\": -1.7251558,\n",
            "            \"B\": -3.3261366,\n",
            "            \"Br\": -1.4657534,\n",
            "            \"Bring\": -2.48131,\n",
            "            \"Repl\": -3.2820647\n",
            "          },\n",
            "          {\n",
            "            \"anches\": -6.3301506,\n",
            "            \"ings\": -0.02375303,\n",
            "            \"isk\": -5.532279,\n",
            "            \"ushes\": -6.3087573,\n",
            "            \"ushing\": -4.3077283\n",
            "          },\n",
            "          {\n",
            "            \" a\": -0.61839855,\n",
            "            \" an\": -2.9688954,\n",
            "            \" new\": -3.7182975,\n",
            "            \" the\": -2.685787,\n",
            "            \" with\": -2.8566692\n",
            "          },\n",
            "          {\n",
            "            \" blanket\": -3.3916323,\n",
            "            \" change\": -3.1433556,\n",
            "            \" chill\": -2.5223124,\n",
            "            \" frost\": -2.5861468,\n",
            "            \" new\": -1.7028582\n",
            "          },\n",
            "          {\n",
            "            \" kind\": -3.0522156,\n",
            "            \" life\": -2.2337353,\n",
            "            \" season\": -1.1125957,\n",
            "            \" start\": -3.2520714,\n",
            "            \"ness\": -2.6292937\n",
            "          },\n",
            "          {\n",
            "            \" near\": -2.6273215,\n",
            "            \" of\": -1.0125955,\n",
            "            \" so\": -3.0437338,\n",
            "            \" to\": -1.534611,\n",
            "            \"'s\": -2.0518553\n",
            "          },\n",
            "          {\n",
            "            \" care\": -2.0801058,\n",
            "            \" change\": -1.129323,\n",
            "            \" cheer\": -2.4924977,\n",
            "            \" despair\": -2.2319539,\n",
            "            \" life\": -2.232159\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -4.6504297,\n",
            "            \",\": -2.626349,\n",
            "            \".\": -0.12659872,\n",
            "            \";\": -4.505671,\n",
            "            \"<|endoftext|>\": -4.1542287\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -1.2070717,\n",
            "            \" \": -3.798235,\n",
            "            \"  \": -7.430582,\n",
            "            \"    \": -9.405072,\n",
            "            \"<|endoftext|>\": -0.38911083\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -3.6735883,\n",
            "            \" \\u00a7\\u00a7\": -0.26538202,\n",
            "            \"+\": -5.0213556,\n",
            "            \"Q\": -5.1455884,\n",
            "            \"The\": -4.3424964\n",
            "          },\n",
            "          {\n",
            "            \" ---\": -6.333516,\n",
            "            \" 10\": -6.706192,\n",
            "            \" 1000\": -3.789156,\n",
            "            \" COM\": -4.7898893,\n",
            "            \" FILE\": -0.03855895\n",
            "          },\n",
            "          {\n",
            "            \" READ\": -0.7637307,\n",
            "            \" app\": -3.8852105,\n",
            "            \" filename\": -3.1056008,\n",
            "            \" lib\": -4.1590443,\n",
            "            \" src\": -2.442969\n",
            "          }\n",
            "        ]\n",
            "      },\n",
            "      \"text\": \"\\n\\nThe chill of winter air,\\nBrings a new season of change.\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1669870359,\n",
            "  \"id\": \"cmpl-6IVqpvzk2FnKxF3xD0kmpF3GYrkD0\",\n",
            "  \"model\": \"text-davinci-003\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 17,\n",
            "    \"prompt_tokens\": 40,\n",
            "    \"total_tokens\": 57\n",
            "  }\n",
            "}\n",
            "EQUAL!\n",
            "[['\\n', '\\n\\nThe chill of winter air', False], ['\\n\\n', '\\n\\nThe chill of winter air', False], ['\\n\\nThe', '\\n\\nThe chill of winter air', False], ['\\n\\nThe chill', '\\n\\nThe chill of winter air', False], ['\\n\\nThe chill of', '\\n\\nThe chill of winter air', False], ['\\n\\nThe chill of winter', '\\n\\nThe chill of winter air', False], ['\\n\\nThe chill of winter air', '\\n\\nThe chill of winter air', True]]\n",
            "('\\n\\nThe chill of winter air ', 6)\n",
            "1\n",
            "print line 2 \n",
            "\n",
            "Leaves fall away soon\n",
            "\n",
            "The chill of winter air brings\n",
            "\n",
            "\n",
            "A new season begins,\n",
            "Snowflakes drift from the sky,\n",
            "A fresh start awaits.\n",
            "gen poem ['\\n\\n', 'A', 'new', 'season', 'begins', ',', '\\n', 'Snowflakes', 'drift', 'from', 'the', 'sky', ',', '\\n', 'A', 'fresh', 'start', 'awaits', '.']\n",
            "('\\n\\nA new season', 4)\n",
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": {\n",
            "        \"text_offset\": [\n",
            "          188,\n",
            "          189,\n",
            "          190,\n",
            "          191,\n",
            "          195,\n",
            "          202,\n",
            "          209,\n",
            "          210,\n",
            "          211,\n",
            "          215,\n",
            "          217,\n",
            "          221,\n",
            "          227,\n",
            "          232,\n",
            "          236,\n",
            "          240,\n",
            "          241,\n",
            "          242,\n",
            "          243,\n",
            "          249,\n",
            "          255,\n",
            "          262,\n",
            "          263,\n",
            "          263\n",
            "        ],\n",
            "        \"token_logprobs\": [\n",
            "          -0.10960683,\n",
            "          -6.21807e-05,\n",
            "          -1.2939956,\n",
            "          -1.8788062,\n",
            "          -0.8716,\n",
            "          -1.1422831,\n",
            "          -0.87668574,\n",
            "          -0.15764281,\n",
            "          -1.5174534,\n",
            "          -0.42821616,\n",
            "          -6.6619094e-07,\n",
            "          -1.7490027,\n",
            "          -0.97222656,\n",
            "          -0.08778768,\n",
            "          -0.020726826,\n",
            "          -0.27440545,\n",
            "          -0.0070904163,\n",
            "          -1.7773592,\n",
            "          -1.4128007,\n",
            "          -0.22031757,\n",
            "          -0.34825945,\n",
            "          -0.3552434,\n",
            "          -7.6605895e-05,\n",
            "          -0.14493804\n",
            "        ],\n",
            "        \"tokens\": [\n",
            "          \"\\n\",\n",
            "          \"\\n\",\n",
            "          \"A\",\n",
            "          \" new\",\n",
            "          \" season\",\n",
            "          \" begins\",\n",
            "          \",\",\n",
            "          \"\\n\",\n",
            "          \"Snow\",\n",
            "          \"fl\",\n",
            "          \"akes\",\n",
            "          \" drift\",\n",
            "          \" from\",\n",
            "          \" the\",\n",
            "          \" sky\",\n",
            "          \",\",\n",
            "          \"\\n\",\n",
            "          \"A\",\n",
            "          \" fresh\",\n",
            "          \" start\",\n",
            "          \" awaits\",\n",
            "          \".\",\n",
            "          \"<|endoftext|>\",\n",
            "          \" \\u00a7\\u00a7\"\n",
            "        ],\n",
            "        \"top_logprobs\": [\n",
            "          {\n",
            "            \"\\n\": -0.10960683,\n",
            "            \"\\n\\n\": -4.2166376,\n",
            "            \" \": -2.4307318,\n",
            "            \"  \": -8.105022,\n",
            "            \"<|endoftext|>\": -7.185756\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -6.21807e-05,\n",
            "            \"\\n\\n\": -14.6797285,\n",
            "            \" \": -9.745158,\n",
            "            \"  \": -14.081633,\n",
            "            \"    \": -13.586821\n",
            "          },\n",
            "          {\n",
            "            \"A\": -1.2939956,\n",
            "            \"B\": -3.051813,\n",
            "            \"Sil\": -3.1618943,\n",
            "            \"Snow\": -3.0047174,\n",
            "            \"The\": -2.118491\n",
            "          },\n",
            "          {\n",
            "            \" blanket\": -3.0412967,\n",
            "            \" new\": -1.8788062,\n",
            "            \" reminder\": -1.8986473,\n",
            "            \" silent\": -3.0155842,\n",
            "            \" time\": -2.9220743\n",
            "          },\n",
            "          {\n",
            "            \" chapter\": -2.9088218,\n",
            "            \" cycle\": -3.1277893,\n",
            "            \" landscape\": -3.1008651,\n",
            "            \" season\": -0.8716,\n",
            "            \" year\": -2.6264627\n",
            "          },\n",
            "          {\n",
            "            \" arrives\": -2.2542338,\n",
            "            \" awaits\": -2.4634395,\n",
            "            \" begins\": -1.1422831,\n",
            "            \" is\": -2.7092385,\n",
            "            \"'s\": -3.2055116\n",
            "          },\n",
            "          {\n",
            "            \" anew\": -2.387896,\n",
            "            \" here\": -3.1490166,\n",
            "            \" now\": -1.6949925,\n",
            "            \" soon\": -2.4582467,\n",
            "            \",\": -0.87668574\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -0.15764281,\n",
            "            \" \": -3.2757876,\n",
            "            \" cold\": -4.727218,\n",
            "            \" snow\": -4.4520345,\n",
            "            \"<|endoftext|>\": -5.198151\n",
            "          },\n",
            "          {\n",
            "            \"A\": -2.5522273,\n",
            "            \"Br\": -3.0926924,\n",
            "            \"F\": -2.858097,\n",
            "            \"Snow\": -1.5174534,\n",
            "            \"The\": -3.098881\n",
            "          },\n",
            "          {\n",
            "            \" blankets\": -2.6126719,\n",
            "            \" covers\": -4.1097364,\n",
            "            \" dr\": -4.204837,\n",
            "            \"fl\": -0.42821616,\n",
            "            \"y\": -3.3417108\n",
            "          },\n",
            "          {\n",
            "            \"ak\": -15.989873,\n",
            "            \"aked\": -15.442865,\n",
            "            \"akes\": -6.6619094e-07,\n",
            "            \"aking\": -15.793848,\n",
            "            \"owers\": -16.768097\n",
            "          },\n",
            "          {\n",
            "            \" dance\": -2.8499577,\n",
            "            \" drift\": -1.7490027,\n",
            "            \" in\": -3.148166,\n",
            "            \" softly\": -2.9343357,\n",
            "            \" start\": -2.8083267\n",
            "          },\n",
            "          {\n",
            "            \" down\": -1.6749749,\n",
            "            \" from\": -0.97222656,\n",
            "            \" in\": -2.4723516,\n",
            "            \" through\": -3.2610936,\n",
            "            \" to\": -1.6191411\n",
            "          },\n",
            "          {\n",
            "            \" above\": -3.454276,\n",
            "            \" on\": -4.6898994,\n",
            "            \" skies\": -5.241333,\n",
            "            \" sky\": -3.8904276,\n",
            "            \" the\": -0.08778768\n",
            "          },\n",
            "          {\n",
            "            \" clouds\": -5.768474,\n",
            "            \" heavens\": -7.566272,\n",
            "            \" night\": -8.813527,\n",
            "            \" skies\": -4.1128993,\n",
            "            \" sky\": -0.020726826\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -2.8900566,\n",
            "            \",\": -0.27440545,\n",
            "            \".\": -1.9732523,\n",
            "            \";\": -4.3675957,\n",
            "            \"<|endoftext|>\": -4.3792706\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -0.0070904163,\n",
            "            \" \": -5.17203,\n",
            "            \"  \": -9.7728615,\n",
            "            \"<|endoftext|>\": -7.1534314,\n",
            "            \"A\": -8.715245\n",
            "          },\n",
            "          {\n",
            "            \"A\": -1.7773592,\n",
            "            \"Bring\": -2.659054,\n",
            "            \"Nature\": -2.0959628,\n",
            "            \"The\": -2.6704733,\n",
            "            \"Time\": -3.4028704\n",
            "          },\n",
            "          {\n",
            "            \" beautiful\": -3.2421548,\n",
            "            \" blanket\": -2.5224729,\n",
            "            \" fresh\": -1.4128007,\n",
            "            \" time\": -2.544543,\n",
            "            \" winter\": -3.0145175\n",
            "          },\n",
            "          {\n",
            "            \" blanket\": -2.5785024,\n",
            "            \" coat\": -3.869911,\n",
            "            \" start\": -0.22031757,\n",
            "            \" winter\": -3.6412094,\n",
            "            \",\": -4.5433683\n",
            "          },\n",
            "          {\n",
            "            \" ahead\": -3.7145338,\n",
            "            \" arrives\": -3.4088922,\n",
            "            \" awaits\": -0.34825945,\n",
            "            \" for\": -2.9893699,\n",
            "            \" in\": -2.9157946\n",
            "          },\n",
            "          {\n",
            "            \" all\": -6.754961,\n",
            "            \" now\": -7.84919,\n",
            "            \" us\": -1.2223319,\n",
            "            \".\": -0.3552434,\n",
            "            \"<|endoftext|>\": -6.18733\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -12.172938,\n",
            "            \"\\n\\n\": -11.140754,\n",
            "            \" \": -9.823372,\n",
            "            \"  \": -13.835659,\n",
            "            \"<|endoftext|>\": -7.6605895e-05\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -3.9171271,\n",
            "            \"\\n\\n\": -5.64639,\n",
            "            \" \\u00a7\\u00a7\": -0.14493804,\n",
            "            \"+\": -5.058933,\n",
            "            \"The\": -5.0330405\n",
            "          }\n",
            "        ]\n",
            "      },\n",
            "      \"text\": \"\\n\\nA new season begins,\\nSnowflakes drift from the sky,\\nA fresh start awaits.\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1669870369,\n",
            "  \"id\": \"cmpl-6IVqzOO31Fjowxe5HVi58i5rKhm9L\",\n",
            "  \"model\": \"text-davinci-003\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 22,\n",
            "    \"prompt_tokens\": 48,\n",
            "    \"total_tokens\": 70\n",
            "  }\n",
            "}\n",
            "EQUAL!\n",
            "[['\\n', '\\n\\nA new season', False], ['\\n\\n', '\\n\\nA new season', False], ['\\n\\nA', '\\n\\nA new season', False], ['\\n\\nA new', '\\n\\nA new season', False], ['\\n\\nA new season', '\\n\\nA new season', True]]\n",
            "('\\n\\nA new season is', 5)\n",
            "print line 3 \n",
            "\n",
            "Leaves fall away soon\n",
            "\n",
            "The chill of winter air brings\n",
            "\n",
            "A new season is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "haiku_v3(\"The taste of a cool lemonade refereshing my friends and I on a very hot day in the U.S.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "LK8LYqYeRPDY",
        "outputId": "b11a45ae-7038-4d60-da89-5b58145dc195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('\\n\\nLemonade so sweet', 5)\n",
            "('\\n\\nOn a hot summer day', 6)\n",
            "EQUAL!\n",
            "('\\n\\nOn a hot summer day ', 6)\n",
            "1\n",
            "('\\n\\nWe laugh and smile', 4)\n",
            "EQUAL!\n",
            "('\\n\\nWe laugh and smile in', 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nLemonade so sweet\\n\\nOn a hot summer day bright\\n\\nWe laugh and smile in'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 489
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "haiku_v3(\"The car drives incredibly fast.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "-4mSMyTJClql",
        "outputId": "fef87c77-a56e-4295-c4d3-bb0e9f9e9cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('\\n\\nThe car drives', 3)\n",
            "EQUAL!\n",
            "[['\\n', '\\n\\nThe car drives', False], ['\\n\\n', '\\n\\nThe car drives', False], ['\\n\\nThe', '\\n\\nThe car drives', False], ['\\n\\nThe car', '\\n\\nThe car drives', False], ['\\n\\nThe car drives', '\\n\\nThe car drives', True]]\n",
            "('\\n\\nThe car drives quickly', 5)\n",
            "('\\n\\nThe wind whips past my face', 6)\n",
            "EQUAL!\n",
            "[['\\n', '\\n\\nThe wind whips past my face', False], ['\\n\\n', '\\n\\nThe wind whips past my face', False], ['\\n\\nThe', '\\n\\nThe wind whips past my face', False], ['\\n\\nThe wind', '\\n\\nThe wind whips past my face', False], ['\\n\\nThe wind wh', '\\n\\nThe wind whips past my face', False], ['\\n\\nThe wind whips', '\\n\\nThe wind whips past my face', False], ['\\n\\nThe wind whips past', '\\n\\nThe wind whips past my face', False], ['\\n\\nThe wind whips past my', '\\n\\nThe wind whips past my face', False], ['\\n\\nThe wind whips past my face', '\\n\\nThe wind whips past my face', True]]\n",
            "('\\n\\nThe wind whips past my face ', 6)\n",
            "1\n",
            "('\\n\\nThe thrill of the speed', 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nThe car drives quickly\\n\\nThe wind whips past my face free\\n\\nThe thrill of the speed'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 486
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "haiku_v3(\"The way water flows through the Earth and inside organisms.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WgsqRQYMC7Kl",
        "outputId": "4bd0cbfe-4daa-4bf5-fd09-b33619c39d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The way water flows\n",
            "Through the Earth and inside us\n",
            "Life\n",
            "gen poem ['\\n\\n', 'The', 'way', 'water', 'flows', '\\n', 'Through', 'the', 'Earth', 'and', 'inside', 'us', '\\n', 'Life']\n",
            "('\\n\\nThe way water flows', 5)\n",
            "print line 1 \n",
            "\n",
            "The way water flows\n",
            "\n",
            "\n",
            "It nourishes life, a gift from the gods.\n",
            "gen poem ['\\n\\n', 'It', 'nourishes', 'life', ',', 'a', 'gift', 'from', 'the', 'gods', '.']\n",
            "('\\n\\nIt nourishes life', 5)\n",
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": {\n",
            "        \"text_offset\": [\n",
            "          172,\n",
            "          173,\n",
            "          174,\n",
            "          176,\n",
            "          181,\n",
            "          186,\n",
            "          191,\n",
            "          192,\n",
            "          194,\n",
            "          199,\n",
            "          204,\n",
            "          208,\n",
            "          213,\n",
            "          214,\n",
            "          214\n",
            "        ],\n",
            "        \"token_logprobs\": [\n",
            "          -0.032446254,\n",
            "          -2.8921473e-05,\n",
            "          -2.348636,\n",
            "          -2.3900301,\n",
            "          -0.0010354641,\n",
            "          -1.4520656,\n",
            "          -1.7155892,\n",
            "          -2.5462115,\n",
            "          -2.282167,\n",
            "          -0.91831034,\n",
            "          -0.75326335,\n",
            "          -1.8810323,\n",
            "          -0.07254045,\n",
            "          -0.0007238752,\n",
            "          -0.63225985\n",
            "        ],\n",
            "        \"tokens\": [\n",
            "          \"\\n\",\n",
            "          \"\\n\",\n",
            "          \"It\",\n",
            "          \" nour\",\n",
            "          \"ishes\",\n",
            "          \" life\",\n",
            "          \",\",\n",
            "          \" a\",\n",
            "          \" gift\",\n",
            "          \" from\",\n",
            "          \" the\",\n",
            "          \" gods\",\n",
            "          \".\",\n",
            "          \"<|endoftext|>\",\n",
            "          \" \\u00a7\\u00a7\"\n",
            "        ],\n",
            "        \"top_logprobs\": [\n",
            "          {\n",
            "            \"\\n\": -0.032446254,\n",
            "            \"\\n\\n\": -6.101338,\n",
            "            \" \": -3.527649,\n",
            "            \"  \": -8.161991,\n",
            "            \"   \": -11.652444\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -2.8921473e-05,\n",
            "            \"\\n\\n\": -15.240457,\n",
            "            \" \": -10.609421,\n",
            "            \"  \": -14.00452,\n",
            "            \"    \": -13.325262\n",
            "          },\n",
            "          {\n",
            "            \"A\": -2.508242,\n",
            "            \"In\": -3.2216854,\n",
            "            \"It\": -2.348636,\n",
            "            \"R\": -3.2426007,\n",
            "            \"Through\": -2.7647564\n",
            "          },\n",
            "          {\n",
            "            \" brings\": -2.8021936,\n",
            "            \" is\": -2.9064448,\n",
            "            \" moves\": -2.8867323,\n",
            "            \" nour\": -2.3900301,\n",
            "            \" sust\": -2.5122378\n",
            "          },\n",
            "          {\n",
            "            \"ish\": -9.490103,\n",
            "            \"ished\": -8.841816,\n",
            "            \"ishes\": -0.0010354641,\n",
            "            \"ishing\": -7.1657734,\n",
            "            \"ishment\": -10.532306\n",
            "          },\n",
            "          {\n",
            "            \" all\": -1.8772812,\n",
            "            \" and\": -1.6817495,\n",
            "            \" life\": -1.4520656,\n",
            "            \" the\": -1.9798461,\n",
            "            \" us\": -2.2891617\n",
            "          },\n",
            "          {\n",
            "            \" and\": -2.162703,\n",
            "            \" in\": -2.187201,\n",
            "            \" with\": -2.4023595,\n",
            "            \"'s\": -2.436731,\n",
            "            \",\": -1.7155892\n",
            "          },\n",
            "          {\n",
            "            \" a\": -2.5462115,\n",
            "            \" and\": -3.3009045,\n",
            "            \" both\": -2.8567972,\n",
            "            \" from\": -2.946082,\n",
            "            \" so\": -2.7523692\n",
            "          },\n",
            "          {\n",
            "            \" blessing\": -2.4565387,\n",
            "            \" cycle\": -2.6923966,\n",
            "            \" gentle\": -2.8857102,\n",
            "            \" gift\": -2.282167,\n",
            "            \" vital\": -2.6288905\n",
            "          },\n",
            "          {\n",
            "            \" divine\": -2.8557186,\n",
            "            \" from\": -0.91831034,\n",
            "            \" of\": -1.2458221,\n",
            "            \" that\": -3.609707,\n",
            "            \" to\": -2.797869\n",
            "          },\n",
            "          {\n",
            "            \" Nature\": -2.8828723,\n",
            "            \" above\": -3.0070696,\n",
            "            \" birth\": -2.3406885,\n",
            "            \" nature\": -1.8198948,\n",
            "            \" the\": -0.75326335\n",
            "          },\n",
            "          {\n",
            "            \" Earth\": -2.0244648,\n",
            "            \" gods\": -1.8810323,\n",
            "            \" heavens\": -2.4924433,\n",
            "            \" sky\": -1.93444,\n",
            "            \" universe\": -2.778106\n",
            "          },\n",
            "          {\n",
            "            \" above\": -5.964214,\n",
            "            \",\": -4.0654373,\n",
            "            \".\": -0.07254045,\n",
            "            \";\": -5.987415,\n",
            "            \"<|endoftext|>\": -3.255909\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -10.17722,\n",
            "            \"\\n\\n\": -11.562063,\n",
            "            \" \": -7.3615284,\n",
            "            \"  \": -10.56014,\n",
            "            \"<|endoftext|>\": -0.0007238752\n",
            "          },\n",
            "          {\n",
            "            \"\\n\": -3.3364146,\n",
            "            \" \\u00a7\\u00a7\": -0.63225985,\n",
            "            \"A\": -4.7339597,\n",
            "            \"The\": -3.4948258,\n",
            "            \"This\": -4.824712\n",
            "          }\n",
            "        ]\n",
            "      },\n",
            "      \"text\": \"\\n\\nIt nourishes life, a gift from the gods.\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1669871198,\n",
            "  \"id\": \"cmpl-6IW4MDFNcMHeNY1PWRtMvLek739Sh\",\n",
            "  \"model\": \"text-davinci-003\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 13,\n",
            "    \"prompt_tokens\": 42,\n",
            "    \"total_tokens\": 55\n",
            "  }\n",
            "}\n",
            "EQUAL!\n",
            "EQUAL!\n",
            "EQUAL!\n",
            "[['\\n', '\\n\\nIt nourishes life', False], ['\\n\\n', '\\n\\nIt nourishes life', False], ['\\n\\nIt', '\\n\\nIt nourishes life', False], ['\\n\\nIt nour', '\\n\\nIt nourishes life', False], ['\\n\\nIt nourishes', '\\n\\nIt nourishes life', False], ['\\n\\nIt nourishes life', '\\n\\nIt nourishes life', True]]\n",
            "('\\n\\nIt nourishes life blessing', 7)\n",
            "print line 2 \n",
            "\n",
            "The way water flows\n",
            "\n",
            "It nourishes life blessing\n",
            "\n",
            "\n",
            "A vital part of life,\n",
            "It sustains us all,\n",
            "A precious resource.\n",
            "gen poem ['\\n\\n', 'A', 'vital', 'part', 'of', 'life', ',', '\\n', 'It', 'sustains', 'us', 'all', ',', '\\n', 'A', 'precious', 'resource', '.']\n",
            "('\\n\\nA vital part of', 5)\n",
            "print line 3 \n",
            "\n",
            "The way water flows\n",
            "\n",
            "It nourishes life blessing\n",
            "\n",
            "A vital part of\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nThe way water flows\\n\\nIt nourishes life blessing\\n\\nA vital part of'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 479
        }
      ]
    }
  ]
}